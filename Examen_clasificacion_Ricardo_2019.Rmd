---
title: "Examen_clasificacion_Ricardo_2019"
author: "Ricardo Ocana Martinez"
date: "5/2/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###### EXAMEN de Técnicas de Clasificación 2018/2019 ######

###### Preparación de datos ######

Para la resolución del examen de Técnicas de Clasificación, se va a proceder, en primer lugar, a realizar la carga de librerías que se utilizarán a lo largo del desarrollo del mismo.

```{r, include=FALSE, echo=FALSE}
library(dplyr)
library(tidyr)
library(readxl)
library(pscl)
library(ggplot2)
library(ROCR)
library(car)
library(mvnormtest)
library(klaR)
library(MASS)
library(gmodels)
library(rpart)
library(rpart.plot)
library(party)
library(boot)
library(base)
library(biotools)
library(plyr)
```

Seguidamente, se va a realizar la carga de los datos con los que se trabajará; se hará un pequeño análisis exploratorio y una limpieza pertinente para trabajar correctamente la misma.

En la limpieza, se localizan los NAs, se convierte a factor aquellas variables categóricas que son de otro tipo y se dividen los datos en dos muestras train y test con un 70%-30% respectivamente.

```{r, include=FALSE,echo=FALSE}
datos <- read_xlsx('BDexamen2.xlsx', sheet='bd', col_names = TRUE)

str(datos)
summary(datos)



ExploreNA <- function(datos) {
  TrueNA <- is.na.data.frame(datos)
  SumNA <- colSums(TrueNA)
  PorcentNA <- colSums(TrueNA) / nrow(datos)*100
  VariableNA <- data.frame(SumNA, PorcentNA)
  
  return(VariableNA)
}

ExploreNA(datos)
datos[is.na(datos)] <- 0
ExploreNA(datos)

datos$REGTEN <- as.factor(datos$REGTEN)
datos$TAMAMU <- as.factor(datos$TAMAMU)
datos$DENSIDAD <- as.factor(datos$DENSIDAD)
datos$SEXO <- as.factor(datos$SEXO)
datos$ESTUD <- as.factor(datos$ESTUD)
datos$LAB <- as.factor(datos$LAB)
datos$cat2 <- as.factor(datos$cat2)
datos$cat3 <- as.factor(datos$cat3)
datos$EDAD<- as.numeric(datos$EDAD)

str(datos)

set.seed(123)
train <- sample(nrow(datos), 0.7*nrow(datos))
datos_train <- datos[train,]
datos_test <- datos[-train,]
```

```{r}
str(datos_train)
```


Una vez los datos han sido limpiados y preparados, se representan las variables a predecir o clasificar tanto para el train como para el test con el objetivo de ver si la muestra está balanceada.

```{r, include=TRUE,echo=TRUE}
par(mfrow = c(1,2)) 
plot(as.factor(datos_train$cat2), main = "Muestra de training - cat2") 
plot(as.factor(datos_test$cat2), main = "Muestra de test - cat2")

par(mfrow = c(1,2)) 
plot(as.factor(datos_train$cat3), main = "Muestra de training - cat3") 
plot(as.factor(datos_test$cat3), main = "Muestra de test - cat3")
```
Estos graficos sirven para observar como están de balanceadas nuestras muestras. En este caso, lo hacemos tanto para la variable cat 2 como cat3 que como podemos observar ambas estan balanceadas.

En este punto, tenemos la base de datos lista para realizar todos los analisis.




*ANÁLISIS DISCRIMINANTE* 

Pese a que se acaba de cargar y preparar todos los datos, se ha considerado conveniente realizar el análisis discriminante para volver a cargar la base de datos; pero se va a preparar de una manera diferente, pues los resultados que va a arrojar son mejores. Sin embargo, para el modelo de regresión logística y para el modelo de árboles de decisión, se emplearán los datos tal y como han sido preparados anteriormente.


Para realizar el análisis discriminante, es conveniente comprobar la normalidad y la heterocedasticidad de las variables. Solo se podrán comprobar estas pruebas en la variables numéricas.

Se utilzará Categoria3 como variable a predecir.

```{r,echo=FALSE,include=FALSE}
col_names <- c('TamanoMunicipio', 'DensidadZona', 'Edad', 'Sexo', 'Estudios', 
               'SituacionLaboral', 'Vivienda', 'Superficie', 'Ingresos', 'Categoria2', 'Categoria3')

datos_convertidos <- datos

names(datos_convertidos) <- col_names
str(datos_convertidos)
```

```{r, include=FALSE, echo=FALSE}
datos_convertidos$TamanoMunicipio <- revalue(datos_convertidos$TamanoMunicipio, c("0"="Menos de 10.000 habs", "1"="Mas de 10.000 habs"))
datos_convertidos$DensidadZona <- revalue(datos_convertidos$DensidadZona, c('1' = 'Densamente poblada', 
                                                                            '2' = 'Diseminada', 
                                                                            '3' = 'Intermedia'))
datos_convertidos$Sexo <- revalue(datos_convertidos$Sexo, c('0' = 'Hombre', '1' = 'Mujer'))
datos_convertidos$Estudios <- revalue(datos_convertidos$Estudios, c('1' = 'Educacion Superior', '2' = 'Inferior a ESO', 
                                                                    '3' = 'Primera etapa ESO', '4' = 'Segunda etapa ESO'))
datos_convertidos$SituacionLaboral <- revalue(datos_convertidos$SituacionLaboral, c('1' = 'Inactivos', '2' = 'Ocupado TC', 
                                                                    '3' = 'Ocupado TP', '4' = 'Parado'))
datos_convertidos$Vivienda <- revalue(datos_convertidos$Vivienda, c('0' = 'Alquiler/Hipoteca', '1' = 'No hipoteca, cesión   gratuita/semigratuita o renta antigua'))

datos_convertidos$Categoria3 <- revalue(datos_convertidos$Categoria3, c('1' = 'Consumo bajo-medio', '2' = 'Consumo medio-alto', 
                                                                    '3' = 'Consumo muy bajo'))

```

```{r}
datos_convertidos$Ingresos <- datos_convertidos$Ingresos * 100
datos_convertidos <- datos_convertidos[, -10]
```

```{r}
str(datos_convertidos)
datos_adisc <- datos_convertidos
```

Para poder comprobar la normalidad de las variables, estas van a ser representadas. Las variables de tipo factor también van a ser representadas con gráficos de barras de colores. Se comprobará si existen grandes diferencias entre los consumos de vacuno (cat3) para las diferentes categorías de las variables.

  - (num) En referencia a la Edad, la distribución está claramente desviada hacia la derecha. No parece que haya un reparto heterogéneo según categoría.
  - (num) En referencia a la Superficie, la distribución parece normal, pero tiene algún atípico en la derecha.
  - (num) En referencia a los Ingresos, la distribución parece normal.
  - (factor) En referencia al Tamaño del municipio, no parece que hayan grandes diferencias entre los municipios pequeños y grandes.
  - (factor) En referencia a la Densidad de la zona, tampoco parece que haya grandes diferencias.
  - (factor) En referencia al Sexo, tampoco hay gran diferencia.
  - (factor) En referencia al Nivel de estudios, sí que se aprecia diferencia entre los que más estudios tienen y los que menos.
  - (factor) En referencia a la Situación laboral, sí que se aprecia diferencia entre los inactivos y ocupados a tiempo completo por un lado, y los otros por otro lado.
  - (factor) En referencia al régimen de Vivienda, sí que hay diferencia.
  
```{r, include=T,echo=T}
library(ggplot2)
ggplot(data = datos_adisc, mapping = aes(x = Edad)) +
  geom_bar(mapping = aes(fill = Categoria3))
ggplot(data = datos_adisc, mapping = aes(x = Superficie)) +
  geom_bar(mapping = aes(fill = Categoria3))
ggplot(data = datos_adisc, mapping = aes(x = Ingresos)) +
  geom_bar()
ggplot(data = datos_adisc, mapping = aes(x = TamanoMunicipio)) +
  geom_bar(mapping = aes(fill = Categoria3))
ggplot(data = datos_adisc, mapping = aes(x = DensidadZona)) +
  geom_bar(mapping = aes(fill = Categoria3))
ggplot(data = datos_adisc, mapping = aes(x = Sexo)) +
  geom_bar(mapping = aes(fill = Categoria3))
ggplot(data = datos_adisc, mapping = aes(x = Estudios)) +
  geom_bar(mapping = aes(fill = Categoria3))
ggplot(data = datos_adisc, mapping = aes(x = SituacionLaboral)) +
  geom_bar(mapping = aes(fill = Categoria3))
ggplot(data = datos_adisc, mapping = aes(x = Vivienda)) +
  geom_bar(mapping = aes(fill = Categoria3))
```

Aunque a priori parece que está demostrada la no normalidad de las variables, se va a realizar el test de Saphiro para corroborarlo.
Evidentemente se confirma la no normalidad de todas las variables numéricas.
H0: Es normal, H1: No es normal. Por tanto buscaremos rechazar la hipótesis nula, queremos que nuestros datos no sean normales.
```{r, include=T,echo=T}
data_disc_num <- datos_adisc[, c(3, 8:10)]

cons_muybajo <- data_disc_num %>%
  filter(Categoria3 == "Consumo muy bajo")
cons_bajomedio <- data_disc_num %>%
  filter(Categoria3 == "Consumo bajo-medio")
cons_medioalto <- data_disc_num %>%
  filter(Categoria3 == "Consumo medio-alto")

cons_muybajo <- t(cons_muybajo[,-4])
mshapiro.test(cons_muybajo)
cons_bajomedio <- t(cons_bajomedio[,-4])
mshapiro.test(cons_bajomedio)
cons_medioalto <- t(cons_medioalto[,-4])
mshapiro.test(cons_medioalto)
```

El siguiente paso es comprobar la heterocedasticidad de las variables, para ello se empleará el test BoxM. Se comprobará que la varianza no es constante en los grupos numéricos. 
Además, con el fin de corregir la normalidad, se van a escalar las variables.
H0: homocedasticidad, buscamos rechazar h0 y asi confirmar heterocedasticidad.

```{r}
data_disc_num$Edad <- as.integer(data_disc_num$Edad)
data_disc_num$Superficie <- as.integer(data_disc_num$Superficie)
data_disc_num$Ingresos <- as.integer(data_disc_num$Ingresos)
str(data_disc_num)
```


```{r}
#No tiene que salir
boxM(data = data_disc_num[, 1:3], data_disc_num[,4])
```

```{r}
scale_var <- scale(data_disc_num[,1:3])
data_discriminante_fact <- datos_adisc[, c(1, 2, 4:7, 10)]
data_discriminante_sca <- cbind(scale_var, data_discriminante_fact)
```


Se divide la muestra en train y test.

```{r}
set.seed(123)
muestra <- sample(4220)
muestra <- muestra[1:2954]
data_train <- data_discriminante_sca[muestra, ]
data_test <- data_discriminante_sca[-muestra,]
```

Se realiza el modelo de Análisis Lineal Discriminante. Con este test, se consigue un acierto del 71,95%, que es un poco bajo. Y su matriz de confusion.

```{r}
mod_lineal <- lda(Categoria3 ~ ., data = data_train) 
pred_lineal <- predict(object = mod_lineal, newdata = data_test) 

confusionLDA <- table(data_test$Categoria3, pred_lineal$class, dnn = c("Real", "Predicho"))
confusionLDA
100 * sum(diag(confusionLDA)/sum(confusionLDA))
```


```{r}
plot(pred_lineal$x, col = pred_lineal$class)
```


Ahora se realiza el modelo de Análisis Cuadrático Discriminante. Con este test, se consigue un acierto del 72,27%, que es un poco bajo, pero mejor que el accuracy del LDA.

```{r}
mod_quad <- qda(Categoria3 ~ ., data = data_train)
pred_quad <- predict(object = mod_quad, newdata = data_test)

confusionQDA <- table(data_test$Categoria3, pred_quad$class, dnn = c("Real", "Predicho")) 
confusionQDA
100 * sum(diag(confusionQDA)/sum(confusionQDA))
```


```{r}
partimat(Categoria3 ~ ., data = data_train, method = "qda", plot.matrix = TRUE, col.correct='green', col.wrong='red')
```


Con los resultados que se han obtenido del Análisis Discriminante, se elige el modelo de Análisis Cuadrático Discriminante por obtener un accuracy ligeramente superior al del Análisis Lineal Discriminante.

```{r}
rm(cons_bajomedio)
rm(cons_medioalto)
rm(cons_muybajo)
rm(data_disc_num)
rm(datos_adisc)
rm(data_discriminante_sca)
rm(mod_lineal)
rm(pred_lineal)
rm(mod_quad)
rm(pred_quad)
rm(confusionQDA)
rm(data_test)
rm(data_train)
```


*REGRESIÓN LOGÍSTICA*

En esta parte del desarrollo del problema se va a realizar una regresión logística. Esta regresión re realizará para clasificar la variable cat2. Por ello, se elimina del dataset la variable cat3, pues no tendría sentido realizar una regresión logística con esa variable. Ya que la regresión logística se utiliza generalmente con variables binarias.

*Para esta técnica y la siguiente se empleará la limpieza de datos realizada al inicio de este RMD.

```{r}
datos_train_glm <- datos_train[,-11]

regresion <- glm(cat2 ~ ., family = "binomial", data = datos_train_glm) 
summary(regresion)

stepAIC(regresion, direction = c("both"))

regresion_buena <- glm(cat2 ~ DENSIDAD + LAB + REGTEN + IMPEXAC, family ="binomial", data = datos_train_glm)
summary(regresion_buena)
```
Primeramente definimos nuestro modelo predictivo conn todas las variables, depués mediante el step tanto fordward como backward nos arroja un modelo con otras variables, comparandiolos con el criterio de Akaike el que nos aporta un numero menor de AIC, es el que hemos conseguido con el Step.


```{r}
datos_test_glm <- datos_test[,-11]
prediccion <- predict(regresion_buena, datos_test_glm, type = 'response')
```

Con la predicción hecha, el siguiente paso requiere que se clasifique cada valor de la predicción en 0 o 1. Para ello se va a averiguar cual es el mejor "cutoff" y posteriormente se realizará la clasificación.

```{r}
searchgrid = seq(0.01, 1, 0.01)
result = cbind(searchgrid, NA)
cost1 <- function(r, pi){
  weight1 = 1
  weight0 = 1
  c1 = (r==1)&(pi<pcut) #logical vector - true if actual 1 but predict 0
  c0 = (r==0)&(pi>pcut) #logical vector - true if actual 0 but predict 1
  return(mean(weight1*c1+weight0*c0))
}
 
for(i in 1:length(searchgrid)) {
  pcut <- result[i,1]
  result[i,2] <- cv.glm(data = datos_train_glm, glmfit = regresion_buena, cost = cost1, K=5)$delta[2]
}

result[which.min(result[,2]),]
```

El resultado es un intervaloi de confianza en el que se encuentra nuesto cutt of óptimo. El cutoff óptimo se encontrará entre 0.48 y 0.129. Se va a comprobar cual es el mejor. Después se representa la matriz de confusión para ver la precisión del modelo.

```{r}
matConf_glm <- table(ifelse(prediccion >= 0.48, 1, 0), datos_test_glm$cat2)
matConf_glm
accuracy_glm <-sum(diag(matConf_glm))/sum(matConf_glm)
accuracy_glm
```

Ahora se va a representar la curva ROC

```{r}
 prediccion1 <- prediction(prediccion, datos_test$cat2)
 AUC <- performance(prediccion1, "auc")
 perf <- performance(prediccion1, "tpr", "fpr") 
 plot(perf, colorize = TRUE) # Establecemos el color. 
 abline(a = 0, b = 1) 
 text(0.4, 0.6, paste(AUC@y.name, "\n", round(unlist(AUC@y.values), 3)), cex = 0.7)
```

Con un cutoff de 0.48, se obtiene un accuracy de 0.88 lo cual significa que el modelo de regresión logística es muy bueno. Además, el resultado que arroja la curva ROC es de 0.93, que es un resultado muy aceptable. La conclusión que se extrae es que las variables que mejor predicen el consumo de carne de vacuno en las familias son los ingresos familiares, la situación laboral y si paga o no hipoteca o alquiler. Es evidente que a mayor poder adquisitivo, más asequible es consumir este tipo de producto.

```{r}
rm(regresion)
rm(datos_train_glm)
rm(datos_test_glm)
rm(prediccion)
```



*ÁRBOLES DE DECISIÓN* 

En este análisis de va a realizar un modelo de árboles de decisión. Un árbol de decisión es un mapa de los posibles resultados de una serie de decisiones relacionadas. Permite que un individuo o una organización comparen posibles acciones entre sí según sus costos, probabilidades y beneficios.

```{r}
set.seed(123)
arbol <- rpart(cat2 ~ ., 
               data=datos_train, 
               method="class",
               parms=list(split="information"))

arbol.pred1 <- predict(arbol, datos_test, type="class")

tabla.clasif.arbol1 <- table(datos_test$cat2, arbol.pred1,
                             dnn=c("Actual", "Predicted"))
print(arbol)
tabla.clasif.arbol1
```

Aquí se representa el accuracy del arbol sin podar. Más tarde lo podaremos para comprobar su estabilidad.

```{r}
tcc2 <- 100 * sum(diag(tabla.clasif.arbol1))/sum(tabla.clasif.arbol1)
tcc2
```

Se observa que el accuracy del árbol es del 95%, lo cual es un accuracy buenísimo.

Aquí se representa la importancia de las variables para la construcción del árbol y el gráfico del mismo.

```{r}
arbol$variable.importance

rpart.plot(arbol, box.palette = "GnBu", branch.lty = 3, 
           shadow.col = "gray", 
           nn = TRUE, main = "Árbol de clasificación sin podar")
```
Ahora se va a representar la curva ROC.

```{r}
prediccion_arbol <- predict(arbol, datos_test, type="prob")[,2] 
pred_arbol = prediction(prediccion_arbol, datos_test$cat2) 
AUC <- performance(pred_arbol, "auc")
perf1 <- performance(pred_arbol, "tpr", "fpr")
plot(perf1, colorize = TRUE)
abline(a = 0, b = 1)
text(0.4, 0.6, paste(AUC@y.name, "\n", round(unlist(AUC@y.values), 5)), cex = 0.7)
```

El resultado de la curva ROC es del 98%, lo cual es un resultado muy bueno.
Seguidamente se va a realizar la poda del árbol. Para ello se calculará el mejor CP (parámetro de complejidad relativo error mínimo) y posteriormente se podará. Se podrá comprobar si los resultados del árbol podado son mejores o peores que los del árbol sin podar.

```{r}
arbol$cptable[which.min(arbol$cptable[,"xerror"]),"CP"]
printcp(arbol) 

arbol_podado <- prune(arbol, cp = 0.10688)
```

Ahora se va a calcular, igual que para el árbol anterior, la predicción pertinente con su posterior precisión o accuracy.

```{r}
rpart.plot(arbol_podado, box.palette = "GnBu", branch.lty = 3, 
           shadow.col = "gray", 
           nn = TRUE, main = "Árbol de clasificación podado")

arbol_prediccion <- predict(arbol_podado, datos_test, type = "class")
arbol_resultado_total <- table(datos_test$cat2, arbol_prediccion,
                                dnn = c("Actual", "Predicted"))

tcc1 <- 100 * sum(diag(arbol_resultado_total))/sum(arbol_resultado_total)
tcc1
```

El accuracy del árbol podado es del 82%, este resultado es muy bueno también; sin embargo, no alcanza el resultado del accuracy del árbol sin podar, así que se aceptará como mejor resultado el del árbol sin podar. A continuación, se representa la curva ROC de este árbol.

```{r}
prediccion_arbol2 <- predict(arbol_podado, datos_test, type="prob")[,2] 
pred_arbol2 = prediction(prediccion_arbol2, datos_test$cat2) 
AUC2 <- performance(pred_arbol2, "auc")
perf2 <- performance(pred_arbol2, "tpr", "fpr")
plot(perf2, colorize = TRUE)
abline(a = 0, b = 1)
text(0.4, 0.6, paste(AUC2@y.name, "\n", round(unlist(AUC2@y.values), 5)), cex = 0.7)
```

Como era de esperar, el resultado de esta curva ROC es del 81%, inferior al anterior, por lo que damos por válido el mejor árbol que es el árbol sin podar.

```{r}
rm(prediccion_arbol)
rm(prediccion_arbol2)
rm(prediccion1)
rm(prediccion)
rm(arbol)
rm(arbol_podado)
rm(arbol_resultado_total)
```



###### COMPARACIÓN DE MODELOS ######

Se va a representar en una tabla todos los resultados obtenidos para finalmente seleccionar qué modelo es el que realiza una mejor clasificación según la categoría 2 o categoría3 (dependiendo del test estadístico)

La siguiente tabla de muestra la precisión y la curva ROC de todos los modelos:


#|           | Regresión Logística | Análisis discriminante_LDA | Análisis discriminante_QDA | Árbol de clasificación   |
#|-----------|---------------------|----------------------------|----------------------------|--------------------------|
#| Curva ROC | 0.930               | -.---                      | -.---                      | 0.984                    |
#| Accuracy  | 88.32               | 71.95                      | 72.27                      | 95.06                    |


Tomando todo ello en su conjunto, se considera que la técnica de árboles de decisión (en este caso, sin podar) es la que mejor clasificación establece para la variable a predecir, por tener el mejor accuracy de todos, así como una mejor curva ROC, comparado con el resto de los modelos.
